{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"scruby-return-dict","text":"<p> Plugin for Scruby - In search methods, returns result as json string. <p> </p> </p> <p>   scruby-return-json is a plugin for the Scruby project. </p> <p></p> <p></p> <p></p>"},{"location":"pages/installation/","title":"Installation","text":"<pre><code>uv add scruby-return-json\n</code></pre>"},{"location":"pages/plugin/","title":"Plugin","text":"<p>Scruby-Return-Json Plugin.</p>"},{"location":"pages/plugin/#scruby_return_json.plugin.ReturnJson","title":"<code>ReturnJson</code>","text":"<p>               Bases: <code>ScrubyPlugin</code></p> <p>Scruby-Return-Json Plugin.</p> <p>In search methods, returns result as json string.</p> Source code in <code>src/scruby_return_json/plugin.py</code> <pre><code>class ReturnJson(ScrubyPlugin):\n    \"\"\"Scruby-Return-Json Plugin.\n\n    In search methods, returns result as json string.\n    \"\"\"\n\n    def __init__(self, scruby_self: Scruby) -&gt; None:  # noqa: D107\n        ScrubyPlugin.__init__(self, scruby_self)\n\n    @final\n    @staticmethod\n    async def _task_find(\n        branch_number: int,\n        filter_fn: Callable,\n        hash_reduce_left: str,\n        db_root: str,\n        class_model: Any,\n    ) -&gt; list[str] | None:\n        \"\"\"Task for find documents.\n\n        This method is for internal use.\n\n        Returns:\n            List of documents as json strings or None.\n        \"\"\"\n        branch_number_as_hash: str = f\"{branch_number:08x}\"[hash_reduce_left:]\n        separated_hash: str = \"/\".join(list(branch_number_as_hash))\n        leaf_path = Path(\n            *(\n                db_root,\n                class_model.__name__,\n                separated_hash,\n                \"leaf.json\",\n            ),\n        )\n        docs: list[str] = []\n        if await leaf_path.exists():\n            data_json: bytes = await leaf_path.read_bytes()\n            data: dict[str, str] = orjson.loads(data_json) or {}\n            for _, val in data.items():\n                doc = class_model.model_validate_json(val)\n                if filter_fn(doc):\n                    docs.append(val)\n        return docs or None\n\n    @final\n    async def find_one(\n        self,\n        filter_fn: Callable,\n    ) -&gt; str | None:\n        \"\"\"Asynchronous method for find one document matching the filter.\n\n        Attention:\n            - The search is based on the effect of a quantum loop.\n            - The search effectiveness depends on the number of processor threads.\n\n        Args:\n            filter_fn (Callable): A function that execute the conditions of filtering.\n\n        Returns:\n            One document as json string or None.\n        \"\"\"\n        # Get Scruby instance\n        scruby_self = self.scruby_self()\n        # Variable initialization\n        search_task_fn: Callable = self._task_find\n        branch_numbers: range = range(scruby_self._max_number_branch)\n        hash_reduce_left: int = scruby_self._hash_reduce_left\n        db_root: str = scruby_self._db_root\n        class_model: Any = scruby_self._class_model\n        # Run quantum loop\n        with concurrent.futures.ThreadPoolExecutor(scruby_self._max_workers) as executor:\n            for branch_number in branch_numbers:\n                future = executor.submit(\n                    search_task_fn,\n                    branch_number,\n                    filter_fn,\n                    hash_reduce_left,\n                    db_root,\n                    class_model,\n                )\n                docs = await future.result()\n                if docs is not None:\n                    return docs[0]\n        return None\n\n    @final\n    async def find_many(\n        self,\n        filter_fn: Callable = lambda _: True,\n        limit_docs: int = 100,\n        page_number: int = 1,\n    ) -&gt; list[str] | None:\n        \"\"\"Asynchronous method for find many documents matching the filter.\n\n        Attention:\n            - The search is based on the effect of a quantum loop.\n            - The search effectiveness depends on the number of processor threads.\n\n        Args:\n            filter_fn (Callable): A function that execute the conditions of filtering.\n                                  By default it searches for all documents.\n            limit_docs (int): Limiting the number of documents. By default = 100.\n            page_number (int): For pagination. By default = 1.\n                               Number of documents per page = limit_docs.\n\n        Returns:\n            List of documents as json strings or None.\n        \"\"\"\n        # The `page_number` parameter must not be less than one\n        assert page_number &gt; 0, \"`find_many` =&gt; The `page_number` parameter must not be less than one.\"\n        # Get Scruby instance\n        scruby_self = self.scruby_self()\n        # Variable initialization\n        search_task_fn: Callable = self._task_find\n        branch_numbers: range = range(scruby_self._max_number_branch)\n        hash_reduce_left: int = scruby_self._hash_reduce_left\n        db_root: str = scruby_self._db_root\n        class_model: Any = scruby_self._class_model\n        counter: int = 0\n        number_docs_skippe: int = limit_docs * (page_number - 1) if page_number &gt; 1 else 0\n        result: list[str] = []\n        # Run quantum loop\n        with concurrent.futures.ThreadPoolExecutor(scruby_self._max_workers) as executor:\n            for branch_number in branch_numbers:\n                if number_docs_skippe == 0 and counter &gt;= limit_docs:\n                    return result[:limit_docs]\n                future = executor.submit(\n                    search_task_fn,\n                    branch_number,\n                    filter_fn,\n                    hash_reduce_left,\n                    db_root,\n                    class_model,\n                )\n                docs = await future.result()\n                if docs is not None:\n                    for doc in docs:\n                        if number_docs_skippe == 0:\n                            if counter &gt;= limit_docs:\n                                return result[:limit_docs]\n                            result.append(doc)\n                            counter += 1\n                        else:\n                            number_docs_skippe -= 1\n        return result or None\n</code></pre>"},{"location":"pages/plugin/#scruby_return_json.plugin.ReturnJson.find_many","title":"<code>find_many(filter_fn=lambda _: True, limit_docs=100, page_number=1)</code>  <code>async</code>","text":"<p>Asynchronous method for find many documents matching the filter.</p> Attention <ul> <li>The search is based on the effect of a quantum loop.</li> <li>The search effectiveness depends on the number of processor threads.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>filter_fn</code> <code>Callable</code> <p>A function that execute the conditions of filtering.                   By default it searches for all documents.</p> <code>lambda _: True</code> <code>limit_docs</code> <code>int</code> <p>Limiting the number of documents. By default = 100.</p> <code>100</code> <code>page_number</code> <code>int</code> <p>For pagination. By default = 1.                Number of documents per page = limit_docs.</p> <code>1</code> <p>Returns:</p> Type Description <code>list[str] | None</code> <p>List of documents as json strings or None.</p> Source code in <code>src/scruby_return_json/plugin.py</code> <pre><code>@final\nasync def find_many(\n    self,\n    filter_fn: Callable = lambda _: True,\n    limit_docs: int = 100,\n    page_number: int = 1,\n) -&gt; list[str] | None:\n    \"\"\"Asynchronous method for find many documents matching the filter.\n\n    Attention:\n        - The search is based on the effect of a quantum loop.\n        - The search effectiveness depends on the number of processor threads.\n\n    Args:\n        filter_fn (Callable): A function that execute the conditions of filtering.\n                              By default it searches for all documents.\n        limit_docs (int): Limiting the number of documents. By default = 100.\n        page_number (int): For pagination. By default = 1.\n                           Number of documents per page = limit_docs.\n\n    Returns:\n        List of documents as json strings or None.\n    \"\"\"\n    # The `page_number` parameter must not be less than one\n    assert page_number &gt; 0, \"`find_many` =&gt; The `page_number` parameter must not be less than one.\"\n    # Get Scruby instance\n    scruby_self = self.scruby_self()\n    # Variable initialization\n    search_task_fn: Callable = self._task_find\n    branch_numbers: range = range(scruby_self._max_number_branch)\n    hash_reduce_left: int = scruby_self._hash_reduce_left\n    db_root: str = scruby_self._db_root\n    class_model: Any = scruby_self._class_model\n    counter: int = 0\n    number_docs_skippe: int = limit_docs * (page_number - 1) if page_number &gt; 1 else 0\n    result: list[str] = []\n    # Run quantum loop\n    with concurrent.futures.ThreadPoolExecutor(scruby_self._max_workers) as executor:\n        for branch_number in branch_numbers:\n            if number_docs_skippe == 0 and counter &gt;= limit_docs:\n                return result[:limit_docs]\n            future = executor.submit(\n                search_task_fn,\n                branch_number,\n                filter_fn,\n                hash_reduce_left,\n                db_root,\n                class_model,\n            )\n            docs = await future.result()\n            if docs is not None:\n                for doc in docs:\n                    if number_docs_skippe == 0:\n                        if counter &gt;= limit_docs:\n                            return result[:limit_docs]\n                        result.append(doc)\n                        counter += 1\n                    else:\n                        number_docs_skippe -= 1\n    return result or None\n</code></pre>"},{"location":"pages/plugin/#scruby_return_json.plugin.ReturnJson.find_one","title":"<code>find_one(filter_fn)</code>  <code>async</code>","text":"<p>Asynchronous method for find one document matching the filter.</p> Attention <ul> <li>The search is based on the effect of a quantum loop.</li> <li>The search effectiveness depends on the number of processor threads.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>filter_fn</code> <code>Callable</code> <p>A function that execute the conditions of filtering.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>One document as json string or None.</p> Source code in <code>src/scruby_return_json/plugin.py</code> <pre><code>@final\nasync def find_one(\n    self,\n    filter_fn: Callable,\n) -&gt; str | None:\n    \"\"\"Asynchronous method for find one document matching the filter.\n\n    Attention:\n        - The search is based on the effect of a quantum loop.\n        - The search effectiveness depends on the number of processor threads.\n\n    Args:\n        filter_fn (Callable): A function that execute the conditions of filtering.\n\n    Returns:\n        One document as json string or None.\n    \"\"\"\n    # Get Scruby instance\n    scruby_self = self.scruby_self()\n    # Variable initialization\n    search_task_fn: Callable = self._task_find\n    branch_numbers: range = range(scruby_self._max_number_branch)\n    hash_reduce_left: int = scruby_self._hash_reduce_left\n    db_root: str = scruby_self._db_root\n    class_model: Any = scruby_self._class_model\n    # Run quantum loop\n    with concurrent.futures.ThreadPoolExecutor(scruby_self._max_workers) as executor:\n        for branch_number in branch_numbers:\n            future = executor.submit(\n                search_task_fn,\n                branch_number,\n                filter_fn,\n                hash_reduce_left,\n                db_root,\n                class_model,\n            )\n            docs = await future.result()\n            if docs is not None:\n                return docs[0]\n    return None\n</code></pre>"},{"location":"pages/usage/","title":"Usage","text":"main.py<pre><code>import anyio\nfrom typing import Any\nfrom pydantic import Field\nfrom scruby import Scruby, ScrubyModel, ScrubySettings\nfrom scruby_return_json import ReturnJson\n\n# Plugins connection.\nScrubySettings.plugins = [\n    ReturnJson,\n]\n\n\nclass Car(ScrubyModel):\n    \"\"\"Car model.\"\"\"\n\n    brand: str = Field(strict=True, frozen=True)\n    model: str = Field(strict=True, frozen=True)\n    year: int = Field(strict=True, frozen=True)\n    power_reserve: int = Field(strict=True, frozen=True)\n    description: str = Field(strict=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: f\"{data['brand']}:{data['model']}\",\n    )\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `Car`\n    car_coll = await Scruby.collection(Car)\n    # Create cars.\n    for num in range(1, 10):\n        car = Car(\n            brand=\"Mazda\",\n            model=f\"EZ-6 {num}\",\n            year=2025,\n            power_reserve=600,\n            description=\"Electric cars are the future of the global automotive industry.\",\n        )\n        await car_coll.add_doc(car)\n\n    # Find one car\n    car_json: str | None = await car_coll.plugins.returnJson.find_one(c\n        filter_fn=lambda doc: doc.brand == \"Mazda\" and doc.model == \"EZ-6 9\",\n    )\n    if car_json is not None:\n      print(car_json)\n    else:\n      print(\"Not Found\")\n\n    # Fand many cars\n    car_json_list: list[str] | None = await car_coll.plugins.returnJson.find_many(\n        filter_fn=lambda doc: doc.brand == \"Mazda\",\n    )\n    if car_json_list is not None:\n      print(car_list)\n    else:\n      print(\"Not Found\")\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"}]}